<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Wentong's Blog</title><link>https://weihua0816.github.io/posts/</link><description>Recent content on Wentong's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><copyright>© 2026 Wentong</copyright><lastBuildDate>Mon, 25 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://weihua0816.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>多頭注意力機制 (Multi-Head Attention) 核心筆記</title><link>https://weihua0816.github.io/posts/%E5%A4%9A%E9%A0%AD%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6-multi-head-attention-%E6%A0%B8%E5%BF%83%E7%AD%86%E8%A8%98/</link><pubDate>Mon, 25 Aug 2025 00:00:00 +0000</pubDate><guid>https://weihua0816.github.io/posts/%E5%A4%9A%E9%A0%AD%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6-multi-head-attention-%E6%A0%B8%E5%BF%83%E7%AD%86%E8%A8%98/</guid><description>本文深入探討多頭注意力機制的核心原理與實作細節。</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://weihua0816.github.io/posts/%E5%A4%9A%E9%A0%AD%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6-multi-head-attention-%E6%A0%B8%E5%BF%83%E7%AD%86%E8%A8%98/feature.jpg"/></item><item><title>揭秘 LLM 大型語言模型的訓練過程：一場精密的植物栽培之旅</title><link>https://weihua0816.github.io/posts/%E6%8F%AD%E7%A7%98-llm-%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A8%93%E7%B7%B4%E9%81%8E%E7%A8%8B%E4%B8%80%E5%A0%B4%E7%B2%BE%E5%AF%86%E7%9A%84%E6%A4%8D%E7%89%A9%E6%A0%BD%E5%9F%B9%E4%B9%8B%E6%97%85/</link><pubDate>Mon, 25 Aug 2025 00:00:00 +0000</pubDate><guid>https://weihua0816.github.io/posts/%E6%8F%AD%E7%A7%98-llm-%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A8%93%E7%B7%B4%E9%81%8E%E7%A8%8B%E4%B8%80%E5%A0%B4%E7%B2%BE%E5%AF%86%E7%9A%84%E6%A4%8D%E7%89%A9%E6%A0%BD%E5%9F%B9%E4%B9%8B%E6%97%85/</guid><description>本文簡潔的介紹了 LLM 大型語言模型的訓練過程，並以植物栽培之旅為比喻，讓讀者更容易理解。</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://weihua0816.github.io/posts/%E6%8F%AD%E7%A7%98-llm-%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A8%93%E7%B7%B4%E9%81%8E%E7%A8%8B%E4%B8%80%E5%A0%B4%E7%B2%BE%E5%AF%86%E7%9A%84%E6%A4%8D%E7%89%A9%E6%A0%BD%E5%9F%B9%E4%B9%8B%E6%97%85/feature.jpg"/></item></channel></rss>