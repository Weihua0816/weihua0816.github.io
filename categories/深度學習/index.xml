<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>深度學習 on Wentong's Blog</title><link>https://weihua0816.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/</link><description>Recent content in 深度學習 on Wentong's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><copyright>© 2026 Wentong</copyright><lastBuildDate>Mon, 25 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://weihua0816.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92/index.xml" rel="self" type="application/rss+xml"/><item><title>多頭注意力機制 (Multi-Head Attention) 核心筆記</title><link>https://weihua0816.github.io/posts/%E5%A4%9A%E9%A0%AD%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6-multi-head-attention-%E6%A0%B8%E5%BF%83%E7%AD%86%E8%A8%98/</link><pubDate>Mon, 25 Aug 2025 00:00:00 +0000</pubDate><guid>https://weihua0816.github.io/posts/%E5%A4%9A%E9%A0%AD%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6-multi-head-attention-%E6%A0%B8%E5%BF%83%E7%AD%86%E8%A8%98/</guid><description>本文深入探討多頭注意力機制的核心原理與實作細節。</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://weihua0816.github.io/posts/%E5%A4%9A%E9%A0%AD%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6-multi-head-attention-%E6%A0%B8%E5%BF%83%E7%AD%86%E8%A8%98/feature.jpg"/></item></channel></rss>